{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "# !ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "# !ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "# !mkdir /home/aistudio/external-libraries\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "# import sys \n",
    "# sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: paddlepaddle-gpu in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.1.post101)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (2.22.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (1.15.0)\n",
      "Requirement already satisfied: astor in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (1.16.4)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (4.4.0)\n",
      "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu) (3.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu) (2019.9.11)\n",
      "paddle 2.0.1\n",
      "using CUDAPlace(0) device.\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlepaddle-gpu\r\n",
    "import paddle as paddle\r\n",
    "import os\r\n",
    "# Initialize PaddlePaddle.\r\n",
    "with_gpu = os.getenv('WITH_GPU', '1') != '0'\r\n",
    "import paddle\r\n",
    "print(\"paddle \" + paddle.__version__)\r\n",
    "device = paddle.set_device(\"gpu\")  # 指定设备\r\n",
    "print(\"using {} device.\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] processing [352/352]\n",
      "[10] processing [377/377]\n",
      "[35] processing [341/341]\n",
      "[21] processing [647/647]\n",
      "[27] processing [526/526]\n",
      "[7] processing [352/352]\n",
      "[39] processing [427/427]\n",
      "[33] processing [312/312]\n",
      "[19] processing [302/302]\n",
      "[15] processing [409/409]\n",
      "[6] processing [385/385]\n",
      "[38] processing [381/381]\n",
      "[13] processing [399/399]\n",
      "[37] processing [312/312]\n",
      "[16] processing [342/342]\n",
      "[20] processing [216/216]\n",
      "[30] processing [311/311]\n",
      "[0] processing [232/232]\n",
      "[17] processing [299/299]\n",
      "[8] processing [370/370]\n",
      "[2] processing [269/269]\n",
      "[5] processing [279/279]\n",
      "[31] processing [436/436]\n",
      "[22] processing [365/365]\n",
      "[36] processing [255/255]\n",
      "[9] processing [379/379]\n",
      "[3] processing [75/75]\n",
      "[4] processing [377/377]\n",
      "[32] processing [270/270]\n",
      "[1] processing [360/360]\n",
      "[29] processing [406/406]\n",
      "[12] processing [321/321]\n",
      "[14] processing [347/347]\n",
      "[11] processing [726/726]\n",
      "[23] processing [299/299]\n",
      "[25] processing [540/540]\n",
      "[34] processing [385/385]\n",
      "[28] processing [372/372]\n",
      "[24] processing [308/308]\n",
      "[26] processing [341/341]\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import zipfile\r\n",
    "with zipfile.ZipFile(\"data/data35095/train.zip\") as zf:\r\n",
    "   zf.extractall()\r\n",
    "! mv train data/dataset\r\n",
    "\r\n",
    "import os\r\n",
    "from shutil import copy, rmtree\r\n",
    "import random\r\n",
    "\r\n",
    "\r\n",
    "def mk_file(file_path: str):\r\n",
    "    if os.path.exists(file_path):\r\n",
    "        # 如果文件夹存在，则先删除原文件夹在重新创建\r\n",
    "        rmtree(file_path)\r\n",
    "    os.makedirs(file_path)\r\n",
    "\r\n",
    "# 保证随机可复现\r\n",
    "random.seed(0)\r\n",
    "\r\n",
    "# 将数据集中10%的数据划分到验证集中\r\n",
    "split_rate = 0.1\r\n",
    "\r\n",
    "# 指向你解压后的flower_photos文件夹\r\n",
    "# cwd = os.getcwd()\r\n",
    "data_root = \"data/\"\r\n",
    "origin_garbage_path = \"data/dataset\"\r\n",
    "assert os.path.exists(origin_garbage_path)\r\n",
    "garbage_class = [cla for cla in os.listdir(origin_garbage_path)\r\n",
    "                if os.path.isdir(os.path.join(origin_garbage_path, cla))]\r\n",
    "\r\n",
    "# 建立保存训练集的文件夹\r\n",
    "train_root = os.path.join(data_root, \"train\")\r\n",
    "mk_file(train_root)\r\n",
    "for cla in garbage_class:\r\n",
    "    # 建立每个类别对应的文件夹\r\n",
    "    mk_file(os.path.join(train_root, cla))\r\n",
    "\r\n",
    "# 建立保存验证集的文件夹\r\n",
    "val_root = os.path.join(data_root, \"val\")\r\n",
    "mk_file(val_root)\r\n",
    "for cla in garbage_class:\r\n",
    "    # 建立每个类别对应的文件夹\r\n",
    "    mk_file(os.path.join(val_root, cla))\r\n",
    "\r\n",
    "for cla in garbage_class:\r\n",
    "    cla_path = os.path.join(origin_garbage_path, cla)\r\n",
    "    images = os.listdir(cla_path)\r\n",
    "    num = len(images)\r\n",
    "    # 随机采样验证集的索引\r\n",
    "    eval_index = random.sample(images, k=int(num*split_rate))\r\n",
    "    for index, image in enumerate(images):\r\n",
    "        if image in eval_index:\r\n",
    "            # 将分配至验证集中的文件复制到相应目录\r\n",
    "            image_path = os.path.join(cla_path, image)\r\n",
    "            new_path = os.path.join(val_root, cla)\r\n",
    "            copy(image_path, new_path)\r\n",
    "        else:\r\n",
    "            # 将分配至训练集中的文件复制到相应目录\r\n",
    "            image_path = os.path.join(cla_path, image)\r\n",
    "            new_path = os.path.join(train_root, cla)\r\n",
    "            copy(image_path, new_path)\r\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")  # processing bar\r\n",
    "    print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "\r\n",
    "class GoogLeNet(nn.Layer):\r\n",
    "    def __init__(self, num_classes=1000, aux_logits=True):\r\n",
    "        # 类别个数， 是否使用辅助分类器\r\n",
    "        super(GoogLeNet, self).__init__()\r\n",
    "        self.aux_logits = aux_logits\r\n",
    "\r\n",
    "        self.conv1 = BasicConv2D(3, 64, kernel_size=7, stride=2, padding=3, weight_attr=nn.initializer.KaimingNormal())  # 输入\r\n",
    "        # (224-7+6)/2+1=112\r\n",
    "        # 3*224*224 -> 64*112*112\r\n",
    "        self.maxpool1 = nn.MaxPool2D(3, stride=2, ceil_mode=True)  # 小数的话向上取整\r\n",
    "        # (112-3)/2+1=56\r\n",
    "        # 64*56*56\r\n",
    "\r\n",
    "        self.conv2 = BasicConv2D(64, 64, kernel_size=1, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        # 64*56*56\r\n",
    "        self.conv3 = BasicConv2D(64, 192, kernel_size=3, padding=1, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        # 192*56*56\r\n",
    "        self.maxpool2 = nn.MaxPool2D(3, stride=2, ceil_mode=True)\r\n",
    "        # 192*28*28\r\n",
    "\r\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\r\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\r\n",
    "        self.maxpool3 = nn.MaxPool2D(3, stride=2, ceil_mode=True)\r\n",
    "\r\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\r\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\r\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\r\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\r\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.maxpool4 = nn.MaxPool2D(3, stride=2, ceil_mode=True)\r\n",
    "\r\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\r\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\r\n",
    "\r\n",
    "        if self.aux_logits:\r\n",
    "            self.aux1 = InceptionAux(512, num_classes)  # 输入为4a的输出\r\n",
    "            self.aux2 = InceptionAux(528, num_classes)  # 输入为4d输出\r\n",
    "\r\n",
    "        self.avgpool = nn.AdaptiveAvgPool2D((1, 1))  # 自适应的，参数为输出矩阵的高与宽\r\n",
    "        self.dropout = nn.Dropout(0.4)\r\n",
    "        self.fc = nn.Linear(1024, num_classes, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # N x 3 x 224 x 224\r\n",
    "        x = self.conv1(x)\r\n",
    "        # N x 64 x 112 x 112\r\n",
    "        x = self.maxpool1(x)\r\n",
    "        # N x 64 x 56 x 56\r\n",
    "        x = self.conv2(x)\r\n",
    "        # N x 64 x 56 x 56\r\n",
    "        x = self.conv3(x)\r\n",
    "        # N x 192 x 56 x 56\r\n",
    "        x = self.maxpool2(x)\r\n",
    "\r\n",
    "        # N x 192 x 28 x 28\r\n",
    "        x = self.inception3a(x)\r\n",
    "        # N x 256 x 28 x 28\r\n",
    "        x = self.inception3b(x)\r\n",
    "        # N x 480 x 28 x 28\r\n",
    "        x = self.maxpool3(x)\r\n",
    "        # N x 480 x 14 x 14\r\n",
    "        x = self.inception4a(x)\r\n",
    "        # N x 512 x 14 x 14\r\n",
    "        if self.training and self.aux_logits:    # eval model lose this layer\r\n",
    "            # 判断当前是属于训练模式还是验证模式，训练则为true\r\n",
    "            aux1 = self.aux1(x)\r\n",
    "\r\n",
    "        x = self.inception4b(x)\r\n",
    "        # N x 512 x 14 x 14\r\n",
    "        x = self.inception4c(x)\r\n",
    "        # N x 512 x 14 x 14\r\n",
    "        x = self.inception4d(x)\r\n",
    "        # N x 528 x 14 x 14\r\n",
    "        if self.training and self.aux_logits:    # eval model lose this layer\r\n",
    "            aux2 = self.aux2(x)\r\n",
    "\r\n",
    "        x = self.inception4e(x)\r\n",
    "        # N x 832 x 14 x 14\r\n",
    "        x = self.maxpool4(x)\r\n",
    "        # N x 832 x 7 x 7\r\n",
    "        x = self.inception5a(x)\r\n",
    "        # N x 832 x 7 x 7\r\n",
    "        x = self.inception5b(x)\r\n",
    "        # N x 1024 x 7 x 7\r\n",
    "\r\n",
    "        x = self.avgpool(x)\r\n",
    "        # N x 1024 x 1 x 1\r\n",
    "        x = paddle.flatten(x, 1)\r\n",
    "        # N x 1024\r\n",
    "        x = self.dropout(x)\r\n",
    "        x = self.fc(x)\r\n",
    "        # N x 1000 (num_classes)\r\n",
    "        if self.training and self.aux_logits:   # eval model lose this layer\r\n",
    "            return x, aux2, aux1  # 训练模式返回3个值\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class Inception(nn.Layer):\r\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\r\n",
    "        # 主要有6个参数，第一个是输入深度\r\n",
    "        # 分别对应表中的各结构\r\n",
    "        super(Inception, self).__init__()\r\n",
    "\r\n",
    "        self.branch1 = BasicConv2D(in_channels, ch1x1, kernel_size=1, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        # 改变通道数\r\n",
    "\r\n",
    "        self.branch2 = nn.Sequential(\r\n",
    "            BasicConv2D(in_channels, ch3x3red, kernel_size=1, weight_attr=nn.initializer.KaimingNormal()),  # 降维\r\n",
    "            BasicConv2D(ch3x3red, ch3x3, kernel_size=3, padding=1, weight_attr=nn.initializer.KaimingNormal())   # 保证输出大小等于输入大小\r\n",
    "            # -3+2+1=0\r\n",
    "        )\r\n",
    "        # 必须保证每个branch的输出高宽是相同的\r\n",
    "\r\n",
    "\r\n",
    "        self.branch3 = nn.Sequential(\r\n",
    "            BasicConv2D(in_channels, ch5x5red, kernel_size=1, weight_attr=nn.initializer.KaimingNormal()),\r\n",
    "            BasicConv2D(ch5x5red, ch5x5, kernel_size=5, padding=2, weight_attr=nn.initializer.KaimingNormal())   # 保证输出大小等于输入大小\r\n",
    "            # -5+4+1=0\r\n",
    "        )\r\n",
    "\r\n",
    "        self.branch4 = nn.Sequential(\r\n",
    "            nn.MaxPool2D(kernel_size=3, stride=1, padding=1),  # 大小不变\r\n",
    "            BasicConv2D(in_channels, pool_proj, kernel_size=1, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        branch1 = self.branch1(x)\r\n",
    "        branch2 = self.branch2(x)\r\n",
    "        branch3 = self.branch3(x)\r\n",
    "        branch4 = self.branch4(x)\r\n",
    "        # 分别输入到每个batch中\r\n",
    "\r\n",
    "        outputs = [branch1, branch2, branch3, branch4]\r\n",
    "        # 合并，长宽相同但是channel不一样\r\n",
    "        return paddle.concat(outputs, 1)  # 深度上进行拼接\r\n",
    "\r\n",
    "\r\n",
    "class InceptionAux(nn.Layer):  # 辅助分类器\r\n",
    "    def __init__(self, in_channels, num_classes):  # 输入深度与类别个数\r\n",
    "        super(InceptionAux, self).__init__()\r\n",
    "        self.averagePool = nn.AvgPool2D(kernel_size=5, stride=3)  # 平均池化\r\n",
    "        self.conv = BasicConv2D(in_channels, 128, kernel_size=1, weight_attr=nn.initializer.KaimingNormal())  # output[batch, 128, 4, 4]\r\n",
    "\r\n",
    "        self.fc1 = nn.Linear(2048, 1024, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        self.fc2 = nn.Linear(1024, num_classes, weight_attr=nn.initializer.KaimingNormal())\r\n",
    "        # 全连接层\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\r\n",
    "        x = self.averagePool(x)\r\n",
    "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\r\n",
    "        x = self.conv(x)\r\n",
    "        # N x 128 x 4 x 4\r\n",
    "        x = paddle.flatten(x, 1)\r\n",
    "        # 展平处理\r\n",
    "        x = F.dropout(x, 0.5, training=self.training)\r\n",
    "        # 加入dropout函数\r\n",
    "        # N x 2048\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.dropout(x, 0.5, training=self.training)\r\n",
    "        # N x 1024\r\n",
    "        x = self.fc2(x)\r\n",
    "        # N x num_classes\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "class BasicConv2D(nn.Layer):\r\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\r\n",
    "        # 输入深度与输出深度\r\n",
    "        super(BasicConv2D, self).__init__()\r\n",
    "        self.conv = nn.Conv2D(in_channels, out_channels, **kwargs)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        # conv, relu合在一起\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDAPlace(0) device.\n",
      "using 12980 images for training, 1422 images for validation.\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import time\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from paddle.vision import transforms\r\n",
    "from paddle.vision import datasets\r\n",
    "import paddle.optimizer as optim\r\n",
    "from paddle.static import InputSpec\r\n",
    "\r\n",
    "device = paddle.set_device(\"gpu\")  # 指定设备\r\n",
    "print(\"using {} device.\".format(device))\r\n",
    "\r\n",
    "data_transform = {\r\n",
    "    # 训练集预处理\r\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\r\n",
    "                                 transforms.RandomHorizontalFlip(),\r\n",
    "                                 transforms.ToTensor(),\r\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\r\n",
    "    # 验证集预处理\r\n",
    "    \"val\": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)\r\n",
    "                               transforms.ToTensor(),\r\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\r\n",
    "\r\n",
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\r\n",
    "train_dataset = datasets.DatasetFolder(root=\"data/train\",\r\n",
    "                                     transform=data_transform[\"train\"])\r\n",
    "train_num = len(train_dataset)\r\n",
    "garbage_list = train_dataset.class_to_idx\r\n",
    "cla_dict = dict((val, key) for key, val in garbage_list.items())  \r\n",
    "\r\n",
    "\r\n",
    "json_str = json.dumps(cla_dict, indent=4)\r\n",
    "with open('class_indices.json', 'w') as json_file:\r\n",
    "    json_file.write(json_str)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "batch_size = 128\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset,\r\n",
    "                                    batch_size=batch_size, shuffle=True,\r\n",
    "                                    num_workers=0)\r\n",
    "validate_dataset = datasets.DatasetFolder(root=\"data/val\",\r\n",
    "                                          transform=data_transform[\"val\"])\r\n",
    "val_num = len(validate_dataset)\r\n",
    "validate_loader = paddle.io.DataLoader(validate_dataset,\r\n",
    "                                        batch_size=batch_size, shuffle=True,\r\n",
    "                                        num_workers=0)\r\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num,\r\n",
    "                                                                       val_num))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "net = GoogLeNet(num_classes=40, aux_logits=True)\r\n",
    "loss_function = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(parameters=net.parameters(), learning_rate=0.0003)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 100%[**************************************************->]5.457 \n",
      "96.86560590099543\n",
      "[epoch 1] train_loss: 5.651  val_accuracy: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 100%[**************************************************->]4.880 \n",
      "100.93733469303697\n",
      "[epoch 2] train_loss: 5.221  val_accuracy: 0.158\n",
      "train loss: 100%[**************************************************->]5.142 \n",
      "100.60623106593266\n",
      "[epoch 3] train_loss: 5.022  val_accuracy: 0.184\n",
      "train loss: 100%[**************************************************->]4.840 \n",
      "101.89062007516623\n",
      "[epoch 4] train_loss: 4.871  val_accuracy: 0.185\n",
      "train loss: 100%[**************************************************->]4.712 \n",
      "100.24071261403151\n",
      "[epoch 5] train_loss: 4.741  val_accuracy: 0.231\n",
      "train loss: 100%[**************************************************->]4.507 \n",
      "100.9687779659871\n",
      "[epoch 6] train_loss: 4.601  val_accuracy: 0.205\n",
      "train loss: 100%[**************************************************->]4.360 \n",
      "100.05084817484021\n",
      "[epoch 7] train_loss: 4.484  val_accuracy: 0.243\n",
      "train loss: 100%[**************************************************->]4.591 \n",
      "100.16725850501098\n",
      "[epoch 8] train_loss: 4.360  val_accuracy: 0.250\n",
      "train loss: 100%[**************************************************->]4.387 \n",
      "100.47053188411519\n",
      "[epoch 9] train_loss: 4.275  val_accuracy: 0.271\n",
      "train loss: 100%[**************************************************->]4.266 \n",
      "101.01532214204781\n",
      "[epoch 10] train_loss: 4.175  val_accuracy: 0.292\n",
      "train loss: 100%[**************************************************->]3.376 \n",
      "99.57764906180091\n",
      "[epoch 11] train_loss: 4.080  val_accuracy: 0.297\n",
      "train loss: 100%[**************************************************->]4.260 \n",
      "100.0686287090648\n",
      "[epoch 12] train_loss: 3.964  val_accuracy: 0.304\n",
      "train loss: 100%[**************************************************->]4.496 \n",
      "100.10620247898623\n",
      "[epoch 13] train_loss: 3.917  val_accuracy: 0.297\n",
      "train loss: 100%[**************************************************->]3.805 \n",
      "100.69798507005908\n",
      "[epoch 14] train_loss: 3.800  val_accuracy: 0.357\n",
      "train loss: 100%[**************************************************->]3.506 \n",
      "99.59236865094863\n",
      "[epoch 15] train_loss: 3.704  val_accuracy: 0.329\n",
      "train loss: 100%[**************************************************->]3.574 \n",
      "100.08122281194665\n",
      "[epoch 16] train_loss: 3.651  val_accuracy: 0.343\n",
      "train loss: 100%[**************************************************->]3.452 \n",
      "100.44869171618484\n",
      "[epoch 17] train_loss: 3.621  val_accuracy: 0.376\n",
      "train loss: 100%[**************************************************->]3.352 \n",
      "99.95274478709325\n",
      "[epoch 18] train_loss: 3.563  val_accuracy: 0.387\n",
      "train loss: 100%[**************************************************->]3.349 \n",
      "100.0527486721985\n",
      "[epoch 19] train_loss: 3.445  val_accuracy: 0.377\n",
      "train loss: 100%[**************************************************->]3.668 \n",
      "100.5293298449833\n",
      "[epoch 20] train_loss: 3.395  val_accuracy: 0.391\n",
      "train loss: 100%[**************************************************->]3.487 \n",
      "100.81066024512984\n",
      "[epoch 21] train_loss: 3.393  val_accuracy: 0.387\n",
      "train loss: 100%[**************************************************->]3.434 \n",
      "101.96584312082268\n",
      "[epoch 22] train_loss: 3.282  val_accuracy: 0.417\n",
      "train loss: 90 %[*********************************************->....]3.442  "
     ]
    }
   ],
   "source": [
    "epochs = 200\r\n",
    "best_acc = 0.0\r\n",
    "train_steps = len(train_loader)\r\n",
    "for epoch in range(epochs):\r\n",
    "    # train\r\n",
    "    net.train()  # 启用dropout\r\n",
    "    running_loss = 0.0\r\n",
    "    t1 = time.perf_counter()\r\n",
    "    for step, data in enumerate(train_loader, start=0):\r\n",
    "        images, labels = data\r\n",
    "        logits, aux_logits2, aux_logits1 = net(images)\r\n",
    "        loss0 = loss_function(logits, labels)  # 主分类器\r\n",
    "        loss1 = loss_function(aux_logits1, labels)  # 辅助\r\n",
    "        loss2 = loss_function(aux_logits2, labels)\r\n",
    "        loss = loss0 + loss1 * 0.3 + loss2 * 0.3\r\n",
    "        # 有三个输出\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.clear_grad() # 梯度置零\r\n",
    "\r\n",
    "        # print statistics\r\n",
    "        running_loss += loss.numpy()[0]\r\n",
    "        rate = (step + 1) / len(train_loader)\r\n",
    "        a = \"*\" * int(rate * 50)\r\n",
    "        b = \".\" * int((1 - rate) * 50)\r\n",
    "        loss_num = loss.numpy()[0]\r\n",
    "        print(\"\\rtrain loss: {:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss_num), end=\" \")\r\n",
    "    print()\r\n",
    "    print(time.perf_counter()-t1)\r\n",
    "    \r\n",
    "    # validate\r\n",
    "    net.eval()  # 关闭dropout\r\n",
    "    acc = 0.0  # accumulate accurate number / epoch\r\n",
    "    with paddle.no_grad():  # 禁止跟踪\r\n",
    "        for val_data in validate_loader:\r\n",
    "            val_images, val_labels = val_data\r\n",
    "            outputs = net(val_images)\r\n",
    "            predict_y = outputs.numpy().argmax(axis=1)\r\n",
    "            acc += (val_labels.astype(\"int\").numpy()==outputs.numpy().argmax(axis=1).astype(\"int\")).sum()\r\n",
    "\r\n",
    "        val_accurate = acc / val_num\r\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\r\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\r\n",
    "\r\n",
    "        if val_accurate > best_acc:\r\n",
    "            paddle.jit.save(\r\n",
    "                layer=net,\r\n",
    "                path=\"result\",\r\n",
    "                input_spec=[InputSpec(shape=[1, 3, 224, 224], dtype='float32')])\r\n",
    "\r\n",
    "print('Finished Training')\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "2021-03-31 22:35:04,775 - INFO - font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2021-03-31 22:35:05,265 - INFO - generated new fontManager\n",
      "2021-03-31 22:35:06,055 - WARNING - DataLoader reader thread raised an exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to perform transform [<paddle.vision.transforms.transforms.ToTensor object at 0x7fe8fe0ac390>] with error: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode. and stack:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 117, in __call__\n",
      "    data = f(data)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 273, in __call__\n",
      "    outputs.append(apply_func(inputs[i]))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 347, in _apply_image\n",
      "    return F.to_tensor(img, self.data_format)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/functional.py\", line 91, in to_tensor\n",
      "    return F_pil.to_tensor(pic, data_format)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/functional_pil.py\", line 75, in to_tensor\n",
      "    img = paddle.to_tensor(np.array(pic, copy=False))\n",
      "  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-242>\", line 2, in to_tensor\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 224, in __impl__\n",
      "    ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n",
      "AssertionError: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\n",
      "\n",
      "process: 0% [->.................................................] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 346, in _thread_loop\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 317, in _thread_loop\n",
      "    batch = self._dataset_fetcher.fetch(indices)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 60, in fetch\n",
      "    data = [self.dataset[idx] for idx in batch_indices]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 60, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in batch_indices]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/datasets/folder.py\", line 188, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 122, in __call__\n",
      "    raise e\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 117, in __call__\n",
      "    data = f(data)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 273, in __call__\n",
      "    outputs.append(apply_func(inputs[i]))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/transforms.py\", line 347, in _apply_image\n",
      "    return F.to_tensor(img, self.data_format)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/functional.py\", line 91, in to_tensor\n",
      "    return F_pil.to_tensor(pic, data_format)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/vision/transforms/functional_pil.py\", line 75, in to_tensor\n",
      "    img = paddle.to_tensor(np.array(pic, copy=False))\n",
      "  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-242>\", line 2, in to_tensor\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 224, in __impl__\n",
      "    ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n",
      "AssertionError: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: 100% [**************************************************->] "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "with zipfile.ZipFile(\"data/data35095/test.zip\") as zf:\r\n",
    "   zf.extractall()\r\n",
    "\r\n",
    "data_transform = transforms.Compose(\r\n",
    "    [transforms.Resize((224, 224)),\r\n",
    "     transforms.ToTensor(),\r\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
    "\r\n",
    "# load image\r\n",
    "with open(\"test.txt\",\"w\") as f:\r\n",
    "    for i in range(1,401):\r\n",
    "        img_path = \"test/test\"+str(i)+\".jpg\"\r\n",
    "        assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\r\n",
    "        img = Image.open(img_path)\r\n",
    "\r\n",
    "        # plt.imshow(img)\r\n",
    "        # [N, C, H, W]\r\n",
    "        img = data_transform(img)\r\n",
    "        # expand batch dimension\r\n",
    "        img = paddle.unsqueeze(img, axis=0)\r\n",
    "        # read class_indict\r\n",
    "        json_path = 'class_indices.json'\r\n",
    "        assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\r\n",
    "\r\n",
    "        json_file = open(json_path, \"r\")\r\n",
    "        class_indict = json.load(json_file)\r\n",
    "\r\n",
    "        # create model\r\n",
    "        model = GoogLeNet(num_classes=40, aux_logits=False)\r\n",
    "\r\n",
    "        # load model weights\r\n",
    "        # weights_path = \"AlexNet.pth\"\r\n",
    "        # assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\r\n",
    "        model = paddle.jit.load(\"result\")\r\n",
    "        # model.load_state_dict(torch.load(weights_path))\r\n",
    "\r\n",
    "        model.eval()\r\n",
    "        with paddle.no_grad():\r\n",
    "            # predict class\r\n",
    "            output = paddle.squeeze(model(img)[0])\r\n",
    "            predict = nn.Softmax(axis=0)(output)\r\n",
    "            predict_cla = paddle.argmax(predict).numpy()[0]\r\n",
    "\r\n",
    "        # print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_cla)],\r\n",
    "                                                    #predict.numpy()[predict_cla])\r\n",
    "        # print(print_res)\r\n",
    "    \r\n",
    "        f.write(class_indict[str(predict_cla)]+\"\\n\")\r\n",
    "\r\n",
    "        rateTest = i / 400\r\n",
    "        aTest = \"*\" * int(rateTest * 50)\r\n",
    "        bTest = \".\" * int((1 - rateTest) * 50)\r\n",
    "        print(\"\\rprocess: {:d}% [{}->{}]\".format(int(rateTest * 100), aTest, bTest), end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
